{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCyxRLn1OVJ1H+v+2ZG46V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inesfrsantos/MachineLearning/blob/main/Model_Attempts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download the necessary packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "WJ5E2v5F8dJr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "df = 'https://raw.githubusercontent.com/inesfrsantos/MachineLearning/main/Dataset/CleanedDataset/filtered_data.csv'\n",
        "df = pd.read_csv(df)"
      ],
      "metadata": {
        "id": "Ei1TDa9BfN7r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['image'].apply(lambda x: np.fromstring(x, dtype=np.uint8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrnnh-i7fOCp",
        "outputId": "7e701526-16a7-4e10-e842-3a5b28dd98c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-098b9423becd>:1: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "  X = df['image'].apply(lambda x: np.fromstring(x, dtype=np.uint8))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a fixed image size\n",
        "img_size = (64, 64)\n",
        "\n",
        "# Resize images to the fixed size\n",
        "X_resized = []\n",
        "for img in X.values:\n",
        "    img = Image.fromarray(img)\n",
        "    img = img.resize(img_size)\n",
        "    img = np.asarray(img)\n",
        "    X_resized.append(img)\n",
        "\n",
        "# Stack the resized images\n",
        "X_stacked = np.stack(X_resized).reshape(-1, 64, 64, 1)\n"
      ],
      "metadata": {
        "id": "RfFkMhOCf-sR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_stacked.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voY8NKfetnau",
        "outputId": "f5671d4d-ebec-4690-ae5b-418f2fdf5cb8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38645, 64, 64, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the data into train, test and validation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_stacked, df['label'], test_size=0.2, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
        "\n",
        "print(\"Number of training samples:\", len(X_train))\n",
        "print(\"Number of validation samples:\", len(X_valid))\n",
        "print(\"Number of testing samples:\", len(X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcQLDfKsgUGh",
        "outputId": "f592ce90-74b7-4a19-eaf2-e2bde6a8d68a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 23187\n",
            "Number of validation samples: 7729\n",
            "Number of testing samples: 7729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enconde the labels\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_valid = le.transform(y_valid)\n",
        "y_test = le.transform(y_test)\n",
        "# Convert the labels to one-hot encoding\n",
        "num_classes = 32\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_valid = to_categorical(y_valid, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n"
      ],
      "metadata": {
        "id": "5LuUlh0FjOUQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "n_classes = len(np.unique(y_train))\n",
        "print(n_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6NF50MclvdA",
        "outputId": "35bb30ec-ce40-4ba6-eb9a-eb834ac506d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qgBr8L4tuhi",
        "outputId": "ee91c896-7bb2-487e-c55e-2d2eff10f33e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23187, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDpwWKzYvgTy",
        "outputId": "5801d7e1-a378-45ad-9bf5-a34a7432b5e7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23187, 64, 64, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple self made CNN"
      ],
      "metadata": {
        "id": "rcN-EWTEPRHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define the model architecture\n",
        "def create_model(num_filters=32, kernel_size=(3,3), activation='relu', learning_rate=0.01, batch_size=32):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(num_filters, kernel_size=kernel_size, activation=activation, input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation=activation))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create a KerasClassifier for use with GridSearchCV\n",
        "model = KerasClassifier(build_fn=create_model, epochs=10, verbose=1)\n",
        "\n",
        "# Define the hyperparameters to search over\n",
        "param_grid = {\n",
        "    'num_filters': [32, 64],\n",
        "    'kernel_size': [(3,3), (5,5)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'learning_rate': [0.001, 0.01],\n",
        "    'batch_size': [32, 64]\n",
        "}\n",
        "\n",
        "# Define the GridSearchCV object\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
        "\n",
        "# Fit the GridSearchCV object on the training data\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_result.best_params_\n",
        "\n",
        "# Train the final model using the best hyperparameters\n",
        "final_model = create_model(**best_params)\n",
        "final_model.fit(X_train, y_train, epochs=10, batch_size=best_params['batch_size'], validation_data=(X_valid, y_valid))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qZT6t_cVwEmi",
        "outputId": "779abb48-43ee-4160-bc6b-efb82570a41d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-abf74f495fa0>:20: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_model, epochs=10, verbose=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "484/484 [==============================] - 59s 118ms/step - loss: 10.7068 - accuracy: 0.0355\n",
            "Epoch 2/10\n",
            "484/484 [==============================] - 58s 121ms/step - loss: 3.4520 - accuracy: 0.0412\n",
            "Epoch 3/10\n",
            "484/484 [==============================] - 57s 118ms/step - loss: 3.4480 - accuracy: 0.0438\n",
            "Epoch 4/10\n",
            "484/484 [==============================] - 57s 118ms/step - loss: 3.4444 - accuracy: 0.0477\n",
            "Epoch 5/10\n",
            "484/484 [==============================] - 58s 119ms/step - loss: 3.4410 - accuracy: 0.0476\n",
            "Epoch 6/10\n",
            "484/484 [==============================] - 59s 122ms/step - loss: 3.4367 - accuracy: 0.0481\n",
            "Epoch 7/10\n",
            "484/484 [==============================] - 58s 120ms/step - loss: 3.4347 - accuracy: 0.0474\n",
            "Epoch 8/10\n",
            "484/484 [==============================] - 58s 119ms/step - loss: 3.4355 - accuracy: 0.0495\n",
            "Epoch 9/10\n",
            "484/484 [==============================] - 57s 119ms/step - loss: 3.4307 - accuracy: 0.0502\n",
            "Epoch 10/10\n",
            "484/484 [==============================] - 58s 120ms/step - loss: 3.4368 - accuracy: 0.0488\n",
            "242/242 [==============================] - 7s 28ms/step - loss: 3.4478 - accuracy: 0.0479\n",
            "Epoch 1/10\n",
            "484/484 [==============================] - 57s 116ms/step - loss: 6.4552 - accuracy: 0.0367\n",
            "Epoch 2/10\n",
            "484/484 [==============================] - 57s 117ms/step - loss: 3.4567 - accuracy: 0.0444\n",
            "Epoch 3/10\n",
            "484/484 [==============================] - 58s 120ms/step - loss: 3.4534 - accuracy: 0.0444\n",
            "Epoch 4/10\n",
            "484/484 [==============================] - 56s 116ms/step - loss: 3.4519 - accuracy: 0.0444\n",
            "Epoch 5/10\n",
            "484/484 [==============================] - 56s 116ms/step - loss: 3.4513 - accuracy: 0.0444\n",
            "Epoch 6/10\n",
            "484/484 [==============================] - 58s 119ms/step - loss: 3.4510 - accuracy: 0.0444\n",
            "Epoch 7/10\n",
            "484/484 [==============================] - 57s 117ms/step - loss: 3.4509 - accuracy: 0.0444\n",
            "Epoch 8/10\n",
            "484/484 [==============================] - 56s 117ms/step - loss: 3.4509 - accuracy: 0.0444\n",
            "Epoch 9/10\n",
            "484/484 [==============================] - 58s 119ms/step - loss: 3.4508 - accuracy: 0.0444\n",
            "Epoch 10/10\n",
            "484/484 [==============================] - 57s 118ms/step - loss: 3.4509 - accuracy: 0.0444\n",
            "242/242 [==============================] - 10s 37ms/step - loss: 3.4499 - accuracy: 0.0458\n",
            "Epoch 1/10\n",
            "484/484 [==============================] - 61s 124ms/step - loss: 6.4782 - accuracy: 0.0346\n",
            "Epoch 2/10\n",
            "484/484 [==============================] - 57s 118ms/step - loss: 3.4558 - accuracy: 0.0440\n",
            "Epoch 3/10\n",
            "484/484 [==============================] - 59s 121ms/step - loss: 3.4522 - accuracy: 0.0450\n",
            "Epoch 4/10\n",
            "484/484 [==============================] - 57s 117ms/step - loss: 3.4505 - accuracy: 0.0450\n",
            "Epoch 5/10\n",
            "484/484 [==============================] - 58s 120ms/step - loss: 3.4498 - accuracy: 0.0450\n",
            "Epoch 6/10\n",
            "484/484 [==============================] - 59s 121ms/step - loss: 3.4495 - accuracy: 0.0450\n",
            "Epoch 7/10\n",
            "484/484 [==============================] - 57s 117ms/step - loss: 3.4494 - accuracy: 0.0450\n",
            "Epoch 8/10\n",
            "484/484 [==============================] - 58s 119ms/step - loss: 3.4493 - accuracy: 0.0450\n",
            "Epoch 9/10\n",
            "484/484 [==============================] - 57s 119ms/step - loss: 3.4493 - accuracy: 0.0450\n",
            "Epoch 10/10\n",
            "484/484 [==============================] - 57s 119ms/step - loss: 3.4492 - accuracy: 0.0450\n",
            "242/242 [==============================] - 8s 34ms/step - loss: 3.4535 - accuracy: 0.0446\n",
            "Epoch 1/10\n",
            "484/484 [==============================] - 99s 202ms/step - loss: 12.8816 - accuracy: 0.0424\n",
            "Epoch 2/10\n",
            "484/484 [==============================] - 96s 198ms/step - loss: 3.4568 - accuracy: 0.0452\n",
            "Epoch 3/10\n",
            "484/484 [==============================] - 97s 200ms/step - loss: 3.4535 - accuracy: 0.0452\n",
            "Epoch 4/10\n",
            "484/484 [==============================] - 97s 200ms/step - loss: 3.4518 - accuracy: 0.0452\n",
            "Epoch 5/10\n",
            "484/484 [==============================] - 97s 201ms/step - loss: 3.4511 - accuracy: 0.0452\n",
            "Epoch 6/10\n",
            "484/484 [==============================] - 97s 201ms/step - loss: 3.4507 - accuracy: 0.0452\n",
            "Epoch 7/10\n",
            "484/484 [==============================] - 96s 197ms/step - loss: 3.4506 - accuracy: 0.0452\n",
            "Epoch 8/10\n",
            "484/484 [==============================] - 95s 196ms/step - loss: 3.4505 - accuracy: 0.0452\n",
            "Epoch 9/10\n",
            "484/484 [==============================] - 96s 199ms/step - loss: 3.4505 - accuracy: 0.0452\n",
            "Epoch 10/10\n",
            "484/484 [==============================] - 96s 199ms/step - loss: 3.4505 - accuracy: 0.0452\n",
            "242/242 [==============================] - 11s 44ms/step - loss: 3.4504 - accuracy: 0.0441\n",
            "Epoch 1/10\n",
            "484/484 [==============================] - 102s 210ms/step - loss: 11.1384 - accuracy: 0.0397\n",
            "Epoch 2/10\n",
            "484/484 [==============================] - 101s 208ms/step - loss: 3.4569 - accuracy: 0.0411\n",
            "Epoch 3/10\n",
            "484/484 [==============================] - 100s 207ms/step - loss: 3.4537 - accuracy: 0.0425\n",
            "Epoch 4/10\n",
            "484/484 [==============================] - 101s 208ms/step - loss: 3.4521 - accuracy: 0.0444\n",
            "Epoch 5/10\n",
            "484/484 [==============================] - 98s 203ms/step - loss: 3.4514 - accuracy: 0.0444\n",
            "Epoch 6/10\n",
            "484/484 [==============================] - 101s 209ms/step - loss: 3.4511 - accuracy: 0.0444\n",
            "Epoch 7/10\n",
            "484/484 [==============================] - 97s 200ms/step - loss: 3.4509 - accuracy: 0.0444\n",
            "Epoch 8/10\n",
            "484/484 [==============================] - 97s 199ms/step - loss: 3.4509 - accuracy: 0.0444\n",
            "Epoch 9/10\n",
            "484/484 [==============================] - 97s 200ms/step - loss: 3.4509 - accuracy: 0.0444\n",
            "Epoch 10/10\n",
            "484/484 [==============================] - 98s 203ms/step - loss: 3.4509 - accuracy: 0.0444\n",
            "242/242 [==============================] - 10s 39ms/step - loss: 3.4498 - accuracy: 0.0458\n",
            "Epoch 1/10\n",
            "484/484 [==============================] - 100s 204ms/step - loss: 7.4881 - accuracy: 0.0409\n",
            "Epoch 2/10\n",
            "484/484 [==============================] - 97s 200ms/step - loss: 3.4562 - accuracy: 0.0450\n",
            "Epoch 3/10\n",
            "484/484 [==============================] - 98s 202ms/step - loss: 3.4526 - accuracy: 0.0450\n",
            "Epoch 4/10\n",
            "484/484 [==============================] - 100s 206ms/step - loss: 3.4508 - accuracy: 0.0450\n",
            "Epoch 5/10\n",
            "484/484 [==============================] - 99s 204ms/step - loss: 3.4500 - accuracy: 0.0450\n",
            "Epoch 6/10\n",
            "210/484 [============>.................] - ETA: 56s - loss: 3.4493 - accuracy: 0.0472"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-abf74f495fa0>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Fit the GridSearchCV object on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Get the best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid shape for y: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load packages\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (64, 64, 1)\n",
        "\n",
        "# Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the first convolutional layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=input_shape))\n",
        "\n",
        "# Add the first max pooling layer\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Add the second convolutional layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Add the second max pooling layer\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Add the flatten layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add the dense layer\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Add the dropout layer\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Add the output layer\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "\n",
        "def lr_decay(epoch):\n",
        "    return 0.01 * 0.9 ** epoch\n",
        "\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_decay)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Lvozp7J47hZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_valid, y_valid))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jvPz8ZBhAgx",
        "outputId": "b1bf88a2-d49d-4bb9-d3bf-358a818d97da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "725/725 [==============================] - 264s 362ms/step - loss: 3.8335 - accuracy: 0.0435 - val_loss: 3.4588 - val_accuracy: 0.0454\n",
            "Epoch 2/10\n",
            "725/725 [==============================] - 253s 349ms/step - loss: 3.4528 - accuracy: 0.0438 - val_loss: 3.4556 - val_accuracy: 0.0454\n",
            "Epoch 3/10\n",
            "725/725 [==============================] - 251s 347ms/step - loss: 3.4530 - accuracy: 0.0445 - val_loss: 3.4566 - val_accuracy: 0.0454\n",
            "Epoch 4/10\n",
            "725/725 [==============================] - 253s 350ms/step - loss: 3.4532 - accuracy: 0.0443 - val_loss: 3.4584 - val_accuracy: 0.0454\n",
            "Epoch 5/10\n",
            "725/725 [==============================] - 250s 345ms/step - loss: 3.4531 - accuracy: 0.0436 - val_loss: 3.4580 - val_accuracy: 0.0454\n",
            "Epoch 6/10\n",
            "725/725 [==============================] - 249s 344ms/step - loss: 3.4529 - accuracy: 0.0444 - val_loss: 3.4585 - val_accuracy: 0.0454\n",
            "Epoch 7/10\n",
            "725/725 [==============================] - 250s 345ms/step - loss: 3.4530 - accuracy: 0.0435 - val_loss: 3.4575 - val_accuracy: 0.0454\n",
            "Epoch 8/10\n",
            "725/725 [==============================] - 248s 343ms/step - loss: 3.4531 - accuracy: 0.0446 - val_loss: 3.4559 - val_accuracy: 0.0454\n",
            "Epoch 9/10\n",
            "725/725 [==============================] - 248s 342ms/step - loss: 3.4531 - accuracy: 0.0448 - val_loss: 3.4558 - val_accuracy: 0.0408\n",
            "Epoch 10/10\n",
            "725/725 [==============================] - 249s 344ms/step - loss: 3.4533 - accuracy: 0.0439 - val_loss: 3.4572 - val_accuracy: 0.0454\n",
            "Test loss: 3.4542579650878906\n",
            "Test accuracy: 0.049165479838848114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complex Sef Made CNN"
      ],
      "metadata": {
        "id": "jVXqO13aPIjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the first convolutional layer with 32 filters of size (3, 3), using 'same' padding\n",
        "# Input shape is (64, 64, 1) for grayscale images, and ReLU activation function\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(64, 64, 1), activation='relu'))\n",
        "\n",
        "# Add batch normalization to normalize the activations of the previous layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Add the second convolutional layer with 32 filters of size (3, 3), using 'same' padding\n",
        "# ReLU activation function is used\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "# Add batch normalization to normalize the activations of the previous layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Add max pooling layer with a pool size of (2, 2) to downsample the image\n",
        "# Dropout of 0.25 is applied to randomly set 25% of the input units to 0 during training\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Add the third convolutional layer with 64 filters of size (3, 3), using 'same' padding\n",
        "# ReLU activation function is used\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "# Add batch normalization to normalize the activations of the previous layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Add the fourth convolutional layer with 64 filters of size (3, 3), using 'same' padding\n",
        "# ReLU activation function is used\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "# Add batch normalization to normalize the activations of the previous layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Add max pooling layer with a pool size of (2, 2) to downsample the image\n",
        "# Dropout of 0.25 is applied to randomly set 25% of the input units to 0 during training\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Add the fifth convolutional layer with 128 filters of size (3, 3), using 'same' padding\n",
        "# ReLU activation function is used\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "# Add batch normalization to normalize the activations of the previous layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Add the sixth convolutional layer with 128 filters of size (3, 3), using 'same' padding\n",
        "# ReLU activation function is used\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "# Add batch normalization to normalize the activations of the previous layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Add max pooling layer with a pool size of (2, 2) to downsample the image\n",
        "# Dropout of 0.25 is applied to randomly set 25% of the input units to 0 during training\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Flatten the output from the previous layer to a 1D vector\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a fully connected dense layer with 512 units and ReLU activation function\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "# Add batch normalization to normalize the activations of the previous layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Add Dropout o.5, meaning half of the neurons will be dropped\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Add the output layer with 28 units (one for each class) and softmax activation\n",
        "model.add(Dense(32, activation='softmax'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "z-bFog1fKAXx",
        "outputId": "f1ea2b4d-02b6-4682-b7ec-9b4b24e782f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-fa32be22ea45>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Add the first convolutional layer with 32 filters of size (3, 3), using 'same' padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Input shape is (64, 64, 1) for grayscale images, and ReLU activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Add batch normalization to normalize the activations of the previous layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    254\u001b[0m                     \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                     \u001b[0;34m\"is incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv2d_14\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 28)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load and preprocess data\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = load_and_preprocess_data()\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), padding='same', input_shape=(64, 64, 1), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(32, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50\n"
      ],
      "metadata": {
        "id": "Jn_GQ2hv0341"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The architecture used for Arabic sign language image classification is effective because it includes more layers and parameters, allowing the model to learn more complex features from the images. The use of batch normalization helps to normalize the input, which can improve the convergence of the model during training. The addition of dropout layers helps to prevent overfitting by randomly dropping out nodes during training. The use of multiple convolutional and max pooling layers allows the model to learn hierarchical representations of the input images, capturing both local and global features. This architecture can handle more complex patterns and variations in the input data compared to a simpler model with only a few layers, like the simple CNN."
      ],
      "metadata": {
        "id": "RYixPV--PHfH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GoogLeNet Inspired CNN"
      ],
      "metadata": {
        "id": "pEsjXz6ERwEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 1"
      ],
      "metadata": {
        "id": "Xn85F82zUxu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, Flatten, Dense\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (64, 64, 1)\n",
        "\n",
        "# Input layer\n",
        "input_layer = Input(shape=input_shape)\n",
        "\n",
        "# First convolutional block\n",
        "conv1_1 = Conv2D(64, (1,1), activation='relu', padding='same')(input_layer)\n",
        "conv1_2 = Conv2D(64, (3,3), activation='relu', padding='same')(conv1_1)\n",
        "conv1_3 = Conv2D(192, (3,3), activation='relu', padding='same')(conv1_2)\n",
        "pool1 = MaxPooling2D((3,3), strides=(2,2), padding='same')(conv1_3)\n",
        "\n",
        "# Second convolutional block\n",
        "conv2_1 = Conv2D(64, (1,1), activation='relu', padding='same')(pool1)\n",
        "conv2_2 = Conv2D(128, (3,3), activation='relu', padding='same')(conv2_1)\n",
        "conv2_3 = Conv2D(256, (3,3), activation='relu', padding='same')(conv2_2)\n",
        "pool2 = MaxPooling2D((3,3), strides=(2,2), padding='same')(conv2_3)\n",
        "\n",
        "# Third convolutional block with additional dropout and batch normalization\n",
        "conv3_1 = Conv2D(128, (1,1), activation='relu', padding='same')(pool2)\n",
        "conv3_2 = Conv2D(256, (3,3), activation='relu', padding='same')(conv3_1)\n",
        "conv3_3 = Conv2D(512, (3,3), activation='relu', padding='same')(conv3_2)\n",
        "pool3 = MaxPooling2D((3,3), strides=(2,2), padding='same')(conv3_3)\n",
        "dropout1 = Dropout(0.4)(pool3)\n",
        "batch_norm1 = BatchNormalization()(dropout1)\n",
        "\n",
        "# Fourth convolutional block with additional dropout and batch normalization\n",
        "conv4_1 = Conv2D(256, (1,1), activation='relu', padding='same')(batch_norm1)\n",
        "conv4_2 = Conv2D(512, (3,3), activation='relu', padding='same')(conv4_1)\n",
        "conv4_3 = Conv2D(1024, (3,3), activation='relu', padding='same')(conv4_2)\n",
        "dropout2 = Dropout(0.4)(conv4_3)\n",
        "batch_norm2 = BatchNormalization()(dropout2)\n",
        "\n",
        "# Fifth convolutional block with additional dropout and batch normalization\n",
        "conv5_1 = Conv2D(256, (1,1), activation='relu', padding='same')(batch_norm2)\n",
        "conv5_2 = Conv2D(512, (3,3), activation='relu', padding='same')(conv5_1)\n",
        "conv5_3 = Conv2D(1024, (3,3), activation='relu', padding='same')(conv5_2)\n",
        "dropout3 = Dropout(0.4)(conv5_3)\n",
        "batch_norm3 = BatchNormalization()(dropout3)\n",
        "\n",
        "# Sixth convolutional block with additional dropout and batch normalization\n",
        "conv6_1 = Conv2D(512, (1,1), activation='relu', padding='same')(concat)\n",
        "conv6_2 = Conv2D(1024, (3,3), activation='relu', padding='same')(conv6_1)\n",
        "dropout4 = Dropout(0.4)(conv6_2)\n",
        "batch_norm4 = BatchNormalization()(dropout4)\n",
        "\n",
        "# Seventh convolutional block with additional dropout and batch normalization\n",
        "conv7_1 = Conv2D(256, (1,1), activation='relu', padding='same')(batch_norm4)\n",
        "conv7_2 = Conv2D(512, (3,3), activation='relu', padding='same')(conv7_1)\n",
        "conv7_3 = Conv2D(1024, (3,3), activation='relu', padding='same')(conv7_2)\n",
        "dropout5 = Dropout(0.4)(conv7_3)\n",
        "batch_norm5 = BatchNormalization()(dropout5)\n",
        "\n",
        "# Eighth convolutional block with additional dropout and batch normalization\n",
        "conv8_1 = Conv2D(256, (1,1), activation='relu', padding='same')(batch_norm5)\n",
        "conv8_2 = Conv2D(512, (3,3), strides=(2,2), activation='relu', padding='same')(conv8_1)\n",
        "conv8_3 = Conv2D(1024, (3,3), activation='relu', padding='same')(conv8_2)\n",
        "dropout6 = Dropout(0.4)(conv8_3)\n",
        "batch_norm6 = BatchNormalization()(dropout6)\n",
        "\n",
        "# Ninth convolutional block with additional dropout and batch normalization\n",
        "conv9_1 = Conv2D(512, (1,1), activation='relu', padding='same')(batch_norm6)\n",
        "conv9_2 = Conv2D(1024, (3,3), activation='relu', padding='same')(conv9_1)\n",
        "dropout7 = Dropout(0.4)(conv9_2)\n",
        "batch_norm7 = BatchNormalization()(dropout7)\n",
        "\n",
        "# Flatten the output of the ninth convolutional block\n",
        "flatten = Flatten()(batch_norm7)\n",
        "\n",
        "# Add two fully connected (dense) layers with additional dropout and batch normalization\n",
        "dense1 = Dense(1024, activation='relu')(flatten)\n",
        "dropout8 = Dropout(0.4)(dense1)\n",
        "batch_norm8 = BatchNormalization()(dropout8)\n",
        "dense2 = Dense(10, activation='softmax')(batch_norm8) # output layer with 10 classes\n",
        "\n",
        "# Define the model with the input layer and the output layer\n",
        "model = Model(inputs=input_layer, outputs=dense2)\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "qAeguEpVRLh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The modifications made to the original GoogLeNet architecture are:\n",
        "\n",
        "Using a grayscale input image (so only 1 channel instead of 3)\n",
        "Changing the input image size to 64x64\n",
        "Adding dropout and batch normalization layers after each of the third, fourth, fifth, sixth, seventh, eighth, and ninth convolutional blocks\n",
        "Changing the number of output classes in the last dense layer to 10 (since we don't know what the specific classification task is, but it's common to have 10 classes for image classification problems)"
      ],
      "metadata": {
        "id": "uo4IbX3dVjNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 2"
      ],
      "metadata": {
        "id": "fCFEAdJlUvzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, concatenate, AveragePooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define input shape\n",
        "input_shape = (64, 64, 1)\n",
        "\n",
        "# Define input layer\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "# Define GoogLeNet-like architecture\n",
        "# First convolutional layer\n",
        "conv1_7x7_s2 = Conv2D(64, (7, 7), strides=(2, 2), padding='same', activation='relu')(inputs)\n",
        "\n",
        "# Max pooling layer\n",
        "pool1_3x3_s2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(conv1_7x7_s2)\n",
        "\n",
        "# Second convolutional layer\n",
        "conv2_3x3_reduce = Conv2D(64, (1, 1), padding='same', activation='relu')(pool1_3x3_s2)\n",
        "conv2_3x3 = Conv2D(192, (3, 3), padding='same', activation='relu')(conv2_3x3_reduce)\n",
        "\n",
        "# Max pooling layer\n",
        "pool2_3x3_s2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(conv2_3x3)\n",
        "\n",
        "# Inception module 1\n",
        "inception_3a_1x1 = Conv2D(64, (1, 1), padding='same', activation='relu')(pool2_3x3_s2)\n",
        "\n",
        "# These 3 convolutional layers are added in the modified GoogLeNet architecture.\n",
        "conv3_3x3 = Conv2D(64, (3, 3), padding='same', activation='relu')(pool2_3x3_s2)\n",
        "conv4_5x5 = Conv2D(32, (5, 5), padding='same', activation='relu')(pool2_3x3_s2)\n",
        "conv5_1x1 = Conv2D(32, (1, 1), padding='same', activation='relu')(pool2_3x3_s2)\n",
        "\n",
        "# Concatenate the output of the convolutional layers above\n",
        "concatenate_1 = concatenate([inception_3a_1x1, conv3_3x3, conv4_5x5, conv5_1x1], axis=3)\n",
        "\n",
        "# Inception module 2\n",
        "inception_3b_1x1 = Conv2D(128, (1, 1), padding='same', activation='relu')(concatenate_1)\n",
        "\n",
        "# These 3 convolutional layers are added in the modified GoogLeNet architecture.\n",
        "conv6_3x3 = Conv2D(128, (3, 3), padding='same', activation='relu')(concatenate_1)\n",
        "conv7_5x5 = Conv2D(64, (5, 5), padding='same', activation='relu')(concatenate_1)\n",
        "conv8_1x1 = Conv2D(64, (1, 1), padding='same', activation='relu')(concatenate_1)\n",
        "\n",
        "# Concatenate the output of the convolutional layers above\n",
        "concatenate_2 = concatenate([inception_3b_1x1, conv6_3x3, conv7_5x5, conv8_1x1], axis=3)\n",
        "\n",
        "# Add a fully connected layer with 1024 neurons\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "\n",
        "# Add a dropout layer to prevent overfitting\n",
        "model.add(layers.Dropout(0.4))\n",
        "\n",
        "# Add the final output layer with 10 neurons (one for each class)\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l4KwavxQUu7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The proposed architecture is inspired by GoogLeNet, which is a well-known deep learning architecture used for image classification tasks. In the case of Arabic sign language classification, the proposed model takes grayscale images of size 64x64 pixels as input and passes them through a series of convolutional and pooling layers to extract features at different scales. The added layers in this model help improve its accuracy and enhance the ability of the model to capture complex patterns in the input images.\n",
        "\n",
        "In particular, the inception modules in the proposed architecture are designed to capture both local and global features of the input images, which is essential for recognizing signs in Arabic sign language. Additionally, the added dropout layer helps prevent overfitting by randomly dropping out some of the neurons during training, which improves the model's generalization ability.\n",
        "\n",
        "Overall, the proposed architecture is well-suited for the classification task of Arabic sign language because it can effectively capture the intricate hand gestures and motions that are involved in this language.\n"
      ],
      "metadata": {
        "id": "uaBLlooMVeeu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4jZ5q-veU7u2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}