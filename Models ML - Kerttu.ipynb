{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be27ca26",
   "metadata": {},
   "source": [
    "<h1>Final project</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd1410b",
   "metadata": {},
   "source": [
    "<h2>Simple CNN</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8587a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels\n",
    "X = df['image']\n",
    "y = df['label']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y = tf.keras.utils.to_categorical(y)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 1)), #defines the first convolutional layer of the model. The layer has 32 filters of size 3x3, uses ReLU activation function and expects input images of size 64x64 with 3 color channels.\n",
    "    tf.keras.layers.MaxPooling2D(2, 2), #adds a max pooling layer with a pool size of 2x2. The layer reduces the spatial dimensions of the output from the previous layer by a factor of 2.\n",
    "    tf.keras.layers.Dropout(0.25), #randomly drops out 25% of the input units during training to reduce overfitting.\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), #defines the second convolutional layer of the model. The layer has 64 filters of size 3x3 and uses ReLU activation function.\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(), # flattens the output from the previous layer into a 1D array.\n",
    "    tf.keras.layers.Dense(128, activation='relu'), #adds a fully connected layer with 128 neurons and ReLU activation function.\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(len(encoder.classes_), activation='softmax') #adds the output layer of the model with the number of neurons equal to the number of unique labels in the dataset. The layer uses softmax activation function to output a probability distribution over the labels.\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='nadam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train.to_list(), y_train, epochs=10, validation_data=(X_val.to_list(), y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_val.to_list(), y_val)\n",
    "print(f\"Validation loss: {loss:.4f}\")\n",
    "print(f\"Validation accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ea23d9",
   "metadata": {},
   "source": [
    "<h2>GoogleNet CNN</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3301c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, AveragePooling2D, Flatten, Dense\n",
    "\n",
    "# Define the input shape of the image as a tuple of (64, 64, 3) \n",
    "input_shape = (64, 64, 3)\n",
    "\n",
    "# Define the input tensor\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "# First block\n",
    "x = Conv2D(64, (7,7), strides=(2,2), padding='same', activation='relu')(inputs) #convolutional layer with 64 filters of size (7,7), using stride of 2 and padding same.\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x) #max-pooling layer with pool size (3,3), stride 2, and padding same.\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# Second block\n",
    "x = Conv2D(64, (1,1), activation='relu')(x) # 1x1 convolution with 64 filters and ReLU activation.\n",
    "x = Conv2D(192, (3,3), padding='same', activation='relu')(x) #3x3 convolution with 192 filters, padding same and ReLU activation.\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x) #max-pooling with pool size (3,3), stride 2, and padding same\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# Inception blocks\n",
    "def inception_module(x, filters): #Defines a function called \"inception_module\" that takes two inputs, a tensor and a list of filters.\n",
    "    path1 = Conv2D(filters[0], (1,1), activation='relu')(x) #convolutional layer with the first filter size from the filter list, a kernel size of (1,1), and the ReLU activation function to the input tensor.\n",
    "    path1 = Conv2D(filters[1], (3,3), padding='same', activation='relu')(path1) #Adds another convolutional layer with the second filter size from the filter list, a kernel size of (3,3), the same padding, and the ReLU activation function to the previous layer.\n",
    "\n",
    "    path2 = Conv2D(filters[2], (1,1), activation='relu')(x) #Adds another convolutional layer with the third filter size from the filter list, a kernel size of (1,1), and the ReLU activation function to the input tensor.\n",
    "    path2 = Conv2D(filters[3], (5,5), padding='same', activation='relu')(path2) #Adds another convolutional layer with the fourth filter size from the filter list, a kernel size of (5,5), the same padding, and the ReLU activation function to the previous layer.\n",
    "\n",
    "    path3 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(x)\n",
    "    path3 = Conv2D(filters[4], (1,1), activation='relu')(path3) #applies a 1x1 convolution with the number of filters specified in filters[4] to the output of the max pooling layer path\n",
    "\n",
    "    output = concatenate([path1, path2, path3], axis=-1) #creates an output tensor with a larger number of channels, which contains the outputs of all three paths.\n",
    "\n",
    "    return output\n",
    "\n",
    "#Applies multiple instances of the inception_module function, using different combinations of filter sizes and numbers of channels, to build a deep neural network with multiple Inception modules.\n",
    "x = inception_module(x, [64, 96, 128, 16, 32])\n",
    "x = inception_module(x, [128, 128, 192, 32, 96])\n",
    "#output tensor goes through another max pooling layer with a pool size of 3x3, stride of 2x2, and padding of 'same'. This downsamples the tensor by a factor of 2 in each spatial dimension.\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x)\n",
    "\n",
    "x = inception_module(x, [192, 96, 208, 16, 48])\n",
    "x = inception_module(x, [160, 112, 224, 24, 64])\n",
    "x = inception_module(x, [128, 128, 256, 24, 64])\n",
    "x = inception_module(x, [112, 144, 288, 32, 64])\n",
    "x = inception_module(x, [256, 160, 320, 32, 128])\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x)\n",
    "\n",
    "# Final block\n",
    "x = AveragePooling2D(pool_size=(7,7))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(1000, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation loss: {loss:.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
